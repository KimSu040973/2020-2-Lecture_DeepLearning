{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lgbm-HyperOptu 데모"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 import 및 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from hyperopt import STATUS_OK, Trials, hp, space_eval, tpe, fmin\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "rcParams['figure.figsize'] = (16, 8)       #그림 사이즈 지정\n",
    "plt.style.use('fivethirtyeight')           #그림 기본 스타일\n",
    "pd.set_option('max_columns', 100)          #칼럼 100개 허용\n",
    "pd.set_option(\"display.precision\", 4)      #소수점 4자리허용\n",
    "warnings.simplefilter('ignore')            #경고분 무시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습데이터 로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_file = 'C:\\\\Users\\\\USER\\\\Desktop\\\\Dataset\\\\DataInput\\\\feature.csv'\n",
    "sample_file  = 'C:\\\\Users\\\\USER\\\\Desktop\\\\Dataset\\\\DataInput\\\\sample_submission.csv'\n",
    "tst_file     = 'C:\\\\Users\\\\USER\\\\Desktop\\\\Dataset\\\\DataInput\\\\test.csv'\n",
    "trn_file     = 'C:\\\\Users\\\\USER\\\\Desktop\\\\Dataset\\\\DataInput\\\\train.csv'\n",
    "\n",
    "df= pd.read_csv(feature_file,index_col=0)        #학습/시험 데이터 \n",
    "print(df.shape)                                  #(6113, 32)\n",
    "df.head()                                        #위 5개            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4280,) (4280, 31) (1833, 31)\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:,31].values[:4280]                  #학습_종속\n",
    "df.drop(df.columns[[31]], axis=1, inplace=True)  #독립을 위한 종속 제거\n",
    "trn = df.iloc[:4280].values                      #학습데이터_독립 4280개\n",
    "tst = df.iloc[4280:].values                      #시험데이터_독립 1883개\n",
    "print(y.shape, trn.shape, tst.shape)             #(4280,) (4280, 31) (1833, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습/검증 데이터 구분\n",
    "학습 후 모델의 예측/분류 정확도 계산을 위한 검증데이터 분리\n",
    "\n",
    "#### [Hold-out Validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn, X_val, y_trn, y_val = train_test_split(trn, y, test_size=.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"n_estimators\": 400,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"random_state\": seed,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "#고정 파라미터\n",
    "\n",
    "space = {\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.01), np.log(0.2)),\n",
    "    \"num_iterations\":  hp.choice(\"num_iterations\", [100, 200, 300, 400, 500, 600,800,1000]),\n",
    "    \"num_leaves\": hp.choice(\"num_leaves\", [16, 32, 64, 127, 254]),\n",
    "    \"min_child_samples\": hp.choice(\"min_child_samples\", [5, 10, 15, 20, 25, 30, 35,40,45,55]),\n",
    "    \"colsample_bytree\": hp.quniform(\"colsample_bytree\", .3, .9, 0.1),\n",
    "    \"subsample\": hp.quniform(\"subsample\", .3, .9, 0.1)\n",
    "}\n",
    "#변경 파라미터_넓은 범위와 여러 파라미터 사용시 시간 급증 (주의)\n",
    "\n",
    "# loguniform: 로그함수를 이용해 확률 분포 내에서의 값으로 test\n",
    "# choice: 리스트 값 중 하나로 선택하여 test\n",
    "# quniform: start와 stop사이에서 일정 간격으로 값을 주어 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                           | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 10/10 [00:20<00:00,  2.01s/trial, best loss: 0.21915510262775925]\n"
     ]
    }
   ],
   "source": [
    "def objective(hyperparams):\n",
    "    model = lgb.LGBMClassifier(**params, **hyperparams)\n",
    "    model.fit(X=X_trn, y=y_trn,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_metric=\"multi_logloss\",#멀티클래스_로그 손실함수\n",
    "              early_stopping_rounds=10,\n",
    "              verbose=False)\n",
    "    score = model.best_score_[\"valid_0\"][\"multi_logloss\"]\n",
    "    #측정한 파라미터 중단됐을 때 최고의 성능점수\n",
    "\n",
    "    return {'loss': score, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, trials=trials, algo=tpe.suggest, max_evals=10, verbose=1)\n",
    "# fn=최소화하고 싶은 함수와 파라미터(space), \n",
    "# trials=실행 객체변수, tpe.sugges=알고리즘 선택\n",
    "# max_evals=서치 횟수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'multiclass', 'boosting_type': 'gbdt', 'subsample_freq': 1, 'random_state': 150, 'n_jobs': -1, 'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.0662586865182318, 'min_child_samples': 45, 'n_estimators': 200, 'num_iterations': 300, 'num_leaves': 31, 'subsample': 0.6000000000000001}\n"
     ]
    }
   ],
   "source": [
    "hyperparams = space_eval(space, best)   #검색하여 나온 최적의 파라미터\n",
    "n_best = trials.best_trial['result']['model'].best_iteration_\n",
    "params.update(hyperparams)\n",
    "print(params)                           #업데이트된 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1\n",
    "{'objective': 'multiclass', 'subsample_freq': 1, 'random_state': 150, 'n_jobs': -1,   \n",
    "'boosting_type': 'dart', 'colsample_bytree': 0.6000000000000001,   \n",
    "'learning_rate': 0.028778270063003097, 'n_estimators': 100, 'num_iterations': 1000,  \n",
    "'num_leaves': 31, 'subsample': 0.6000000000000001}\n",
    "90.--\n",
    "\n",
    "#2\n",
    "{'objective': 'multiclass', 'subsample_freq': 1, 'random_state': 150,  \n",
    "'n_jobs': -1, 'boosting_type': 'gbdt', 'colsample_bytree': 0.7000000000000001,   \n",
    "'learning_rate': 0.06316437855450058, 'n_estimators': 600, 'num_leaves': 10,  \n",
    "'subsample': 0.6000000000000001}  \n",
    "91.308\n",
    "\n",
    "#3 \n",
    "{'objective': 'multiclass', 'boosting_type': 'gbdt', 'subsample_freq': 1,   \n",
    " 'random_state': 150, 'n_jobs': -1, 'colsample_bytree': 0.7000000000000001,   \n",
    "  'learning_rate': 0.0662586865182318, 'min_child_samples': 45, 'n_estimators': 200,    \n",
    " 'num_iterations': 300, 'num_leaves': 31, 'subsample': 0.6000000000000001}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold Cross Validation\n",
    "*Stratified N-Fold CV: N-Fold CV에서 각각의 폴드에서 종속변수의 분포가 동일하도록 폴드를 나누는 방식.\n",
    "현재 사용하는 데이터처럼 분류학습에서 종속변수의 범주의 분포가 균일하지 않을 때 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [범주형 > 수치형 변환_종속변수]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "label_str=y\n",
    "label_int=le.fit_transform(label_str).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#93.3216% seed1022\n",
    "p_val = np.zeros((trn.shape[0], n_class))\n",
    "p_tst = np.zeros((tst.shape[0], n_class))\n",
    "#(cv.split(),1)\n",
    "# -  StratifiedKFold 경우, trn,y 독립과 종속(동일 분포를 위해) 인자\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    clf = lgb.LGBMClassifier(**params)\n",
    "    clf.fit(trn[i_trn], y[i_trn],\n",
    "            eval_set=[(trn[i_val], y[i_val])],\n",
    "            eval_metric='multiclass',\n",
    "            early_stopping_rounds=10)\n",
    "    \n",
    "    p_val[i_val, :] = clf.predict_proba(trn[i_val])\n",
    "    #확률로 예측값 초가화\n",
    "    p_tst += clf.predict_proba(tst) / n_fold\n",
    "    #평균 효과를 위해 먼저 폴드 개수만큼 나누어 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "** ( 범주값 출력: clf.pedict(), 확률값출력: clf.predict_proba() ) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{accuracy_score(y, np.argmax(p_val, axis=1)) * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피처 중요도 시각화\n",
    "여러 모델 시각화 대신 각 모델에서 손실 감소에 기여한 피처들의 중요도를 보기 위한 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.DataFrame({'feature': df.columns, 'importance': clf.feature_importances_})\n",
    "imp = imp.sort_values('importance').set_index('feature')\n",
    "imp.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [수치형 > 범주형 변환_종속변수]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt=np.zeros(shape=(1833,))\n",
    "pt = pt.astype(np.int64)\n",
    "for x in range(0,1833):\n",
    "    pt[x] = np.argmax(p_tst[x,:])\n",
    "target=le.inverse_transform(pt)\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub = pd.read_csv(sample_file)\n",
    "#sub['class']\n",
    "sub = pd.read_csv(sample_file)\n",
    "sub['class'] = p_tst\n",
    "sub.to_csv('C:\\\\Users\\\\USER\\\\Desktop\\\\Dataset\\\\sub\\\\lgbmHyper-sub.csv',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
