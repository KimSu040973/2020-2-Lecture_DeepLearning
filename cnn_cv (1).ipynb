{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 링크 \n",
    "X-Ray Pneumonia - CNN, Tensorflow 2.0, Keras [94%]  \n",
    "\n",
    "https://www.kaggle.com/michalbrezk/x-ray-pneumonia-cnn-tensorflow-2-0-keras-94\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random as rn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './input/chest_xray/'\n",
    "# define paths\n",
    "train_normal_dir = path + 'train/NORMAL/'\n",
    "train_pneu_dir = path + 'train/PNEUMONIA/'\n",
    "\n",
    "test_normal_dir = path + 'test/NORMAL/'\n",
    "test_pneu_dir = path + 'test/PNEUMONIA/'\n",
    "\n",
    "val_normal_dir = path + 'val/NORMAL/'\n",
    "val_pneu_dir = path + 'val/PNEUMONIA/'\n",
    "\n",
    "# find all files, our files has extension jpeg\n",
    "train_normal_cases = glob.glob(train_normal_dir + '*jpeg') #1341\n",
    "train_pneu_cases = glob.glob(train_pneu_dir + '*jpeg')#3875\n",
    "\n",
    "test_normal_cases = glob.glob(test_normal_dir + '*jpeg')#234\n",
    "test_pneu_cases = glob.glob(test_pneu_dir + '*jpeg')#390\n",
    "\n",
    "val_normal_cases = glob.glob(val_normal_dir + '*jpeg')#8\n",
    "val_pneu_cases = glob.glob(val_pneu_dir + '*jpeg')#8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make path using / instead of \\\\ ... this may be redudant step\n",
    "train_normal_cases = [x.replace('\\\\', '/') for x in train_normal_cases]\n",
    "train_pneu_cases = [x.replace('\\\\', '/') for x in train_pneu_cases]\n",
    "test_normal_cases = [x.replace('\\\\', '/') for x in test_normal_cases]\n",
    "test_pneu_cases = [x.replace('\\\\', '/') for x in test_pneu_cases]\n",
    "val_normal_cases = [x.replace('\\\\', '/') for x in val_normal_cases]\n",
    "val_pneu_cases = [x.replace('\\\\', '/') for x in val_pneu_cases]\n",
    "\n",
    "\n",
    "# create lists for train, test & validation cases, create labels as well\n",
    "train_list = []\n",
    "test_list = []\n",
    "val_list = []\n",
    "\n",
    "for x in train_normal_cases:\n",
    "    train_list.append([x, 0])\n",
    "    \n",
    "for x in train_pneu_cases:\n",
    "    train_list.append([x, 1])\n",
    "    \n",
    "for x in test_normal_cases:\n",
    "    test_list.append([x, 0])\n",
    "    \n",
    "for x in test_pneu_cases:\n",
    "    test_list.append([x, 1])\n",
    "    \n",
    "for x in val_normal_cases:\n",
    "    val_list.append([x, 0])\n",
    "    \n",
    "for x in val_pneu_cases:\n",
    "    val_list.append([x, 1])\n",
    "\n",
    "\n",
    "# shuffle/randomize data as they were loaded in order: normal cases, then pneumonia cases\n",
    "rn.shuffle(train_list)\n",
    "rn.shuffle(test_list)\n",
    "rn.shuffle(val_list)\n",
    "\n",
    "\n",
    "# create dataframes\n",
    "train_df = pd.DataFrame(train_list, columns=['image', 'label'])\n",
    "test_df = pd.DataFrame(test_list, columns=['image', 'label'])\n",
    "val_df = pd.DataFrame(val_list, columns=['image', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize distribution of cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.countplot(train_df['label'])\n",
    "plt.title('Train data')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.countplot(test_df['label'])\n",
    "plt.title('Test data')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.countplot(val_df['label'])\n",
    "plt.title('Validation data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing_(196,196)\n",
    "process_data - 이미지 로드, 크기 조정, 그레이스케일로 변환, 정규화 및 텐서 흐름에 필요한 차원으로 재조정  \n",
    "compose_dataset - 이미지를 반복하여 2 Numpy 배열 생성. 첫째는 이미지 자체를 매트릭스로 포함하며, 둘째는 레이블을 포함함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (196, 196))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = img/255.0\n",
    "    img = np.reshape(img, (196,196,1))\n",
    "    \n",
    "    return img\n",
    "\n",
    "def compose_dataset(df):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for img_path, label in df.values:\n",
    "        data.append(process_data(img_path))\n",
    "        labels.append(label)\n",
    "        \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (5216, 196, 196, 1), Labels shape: (5216,)\n",
      "Test data shape: (624, 196, 196, 1), Labels shape: (624,)\n",
      "Validation data shape: (16, 196, 196, 1), Labels shape: (16,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = compose_dataset(train_df)\n",
    "X_test, y_test = compose_dataset(test_df)\n",
    "X_val, y_val = compose_dataset(val_df)\n",
    "\n",
    "print('Train data shape: {}, Labels shape: {}'.format(X_train.shape, y_train.shape))\n",
    "print('Test data shape: {}, Labels shape: {}'.format(X_test.shape, y_test.shape))\n",
    "print('Validation data shape: {}, Labels shape: {}'.format(X_val.shape, y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range = 0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n",
    "\n",
    "# fit generator on our train features\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kfold  Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "img_width, img_height, img_num_channels = 196, 196, 1 #gray image channel = 1\n",
    "loss_function = sparse_categorical_crossentropy\n",
    "no_classes = 2\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=8, kernel_size=(7,7), padding='same', activation='relu', input_shape=(196, 196, 1)),\n",
    "        Conv2D(filters=8, kernel_size=(7,7), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3,3)),\n",
    "        \n",
    "        Conv2D(filters=16, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "        Conv2D(filters=16, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3,3)),\n",
    "        \n",
    "        Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "        Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        \n",
    "        Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "        Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        \n",
    "        Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "        Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Flatten(),\n",
    "        Dropout(0.2),\n",
    "        Dense(2, activation='softmax')        \n",
    "    ])\n",
    "    \n",
    "    # compile model\n",
    "    optimizer = Adam(lr=0.0001, decay=1e-5)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for Kfold #1\n",
      "Epoch 1/50\n",
      "261/261 [==============================] - 167s 638ms/step - loss: 0.8318 - accuracy: 0.3229\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 167s 638ms/step - loss: 0.3315 - accuracy: 0.8353\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 167s 639ms/step - loss: 0.2663 - accuracy: 0.8636\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.2247 - accuracy: 0.8804\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 167s 639ms/step - loss: 0.2066 - accuracy: 0.8938\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.1885 - accuracy: 0.9010\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.1803 - accuracy: 0.9084\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.1669 - accuracy: 0.9144\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 167s 641ms/step - loss: 0.1416 - accuracy: 0.9252\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.1502 - accuracy: 0.9274\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.1325 - accuracy: 0.9353\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 167s 642ms/step - loss: 0.1096 - accuracy: 0.9470\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.1068 - accuracy: 0.9487\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.0954 - accuracy: 0.9525\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0851 - accuracy: 0.9585\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0790 - accuracy: 0.9614\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0885 - accuracy: 0.9573\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.0722 - accuracy: 0.9662\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0610 - accuracy: 0.9703\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0604 - accuracy: 0.9708\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0599 - accuracy: 0.9712\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0521 - accuracy: 0.9760\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0634 - accuracy: 0.9708\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 168s 645ms/step - loss: 0.0446 - accuracy: 0.9803\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0530 - accuracy: 0.9756\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0347 - accuracy: 0.9830\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0454 - accuracy: 0.9775\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0301 - accuracy: 0.9866\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0637 - accuracy: 0.9724\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0319 - accuracy: 0.9851\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0225 - accuracy: 0.9899\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0227 - accuracy: 0.9885\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0167 - accuracy: 0.9914\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.0223 - accuracy: 0.9911\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0294 - accuracy: 0.9861\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0177 - accuracy: 0.9909\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0096 - accuracy: 0.9959\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.0306 - accuracy: 0.9885\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0090 - accuracy: 0.9959\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0087 - accuracy: 0.9962\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0064 - accuracy: 0.9969\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0256 - accuracy: 0.9916\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.0170 - accuracy: 0.9914\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 168s 645ms/step - loss: 0.0064 - accuracy: 0.9974\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.0149 - accuracy: 0.9928\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0693 - accuracy: 0.9720\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.0105 - accuracy: 0.9940\n",
      "Score for fold 1: loss of 0.056825265288352966; accuracy of 98.08428883552551%\n",
      "training model for Kfold #2\n",
      "Epoch 1/50\n",
      "261/261 [==============================] - 170s 650ms/step - loss: 0.8292 - accuracy: 0.3139\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 168s 645ms/step - loss: 0.3613 - accuracy: 0.8148\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.2677 - accuracy: 0.8684\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 168s 645ms/step - loss: 0.1913 - accuracy: 0.9099\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.1683 - accuracy: 0.9178\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 169s 647ms/step - loss: 0.1508 - accuracy: 0.9248\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.1375 - accuracy: 0.9346\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 168s 645ms/step - loss: 0.1193 - accuracy: 0.9415\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.1195 - accuracy: 0.9410\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 168s 645ms/step - loss: 0.1026 - accuracy: 0.9538\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 168s 645ms/step - loss: 0.0827 - accuracy: 0.9605\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 168s 645ms/step - loss: 0.0794 - accuracy: 0.9624\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0881 - accuracy: 0.9552\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0616 - accuracy: 0.9674\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 168s 645ms/step - loss: 0.0701 - accuracy: 0.9693\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0511 - accuracy: 0.9782\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 169s 646ms/step - loss: 0.0645 - accuracy: 0.9693\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0481 - accuracy: 0.9768\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0479 - accuracy: 0.9780\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0483 - accuracy: 0.9792\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 168s 645ms/step - loss: 0.0352 - accuracy: 0.9830\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 168s 645ms/step - loss: 0.0445 - accuracy: 0.9803\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0243 - accuracy: 0.9899\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0246 - accuracy: 0.9880\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0396 - accuracy: 0.9808\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0268 - accuracy: 0.9873\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 168s 645ms/step - loss: 0.0197 - accuracy: 0.9919\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0167 - accuracy: 0.9931\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0360 - accuracy: 0.9823\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 168s 645ms/step - loss: 0.0437 - accuracy: 0.9777\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0165 - accuracy: 0.9933\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0094 - accuracy: 0.9959\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.0406 - accuracy: 0.9832\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0380 - accuracy: 0.9820\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0096 - accuracy: 0.9954\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0106 - accuracy: 0.9950\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.0057 - accuracy: 0.9974\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.0060 - accuracy: 0.9976\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0071 - accuracy: 0.9954\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.0045 - accuracy: 0.9978\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 168s 643ms/step - loss: 0.0195 - accuracy: 0.9926\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 168s 644ms/step - loss: 0.0085 - accuracy: 0.9952\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 169s 646ms/step - loss: 0.0145 - accuracy: 0.9933\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 168s 642ms/step - loss: 0.0061 - accuracy: 0.9974\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 167s 641ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 167s 641ms/step - loss: 3.7436e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 167s 641ms/step - loss: 2.1158e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 167s 640ms/step - loss: 3.0164e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 167s 641ms/step - loss: 3.1421e-04 - accuracy: 1.0000\n",
      "Score for fold 2: loss of 0.10772067308425903; accuracy of 98.37008714675903%\n",
      "training model for Kfold #3\n"
     ]
    }
   ],
   "source": [
    "for i, (train, test) in enumerate(kfold.split(X_train, y_train), 1):\n",
    "   \n",
    "    print(f'training model for Kfold #{i}')\n",
    "    callback = EarlyStopping(monitor='loss', patience=6)\n",
    "    \n",
    "    model = get_model()\n",
    "\n",
    "    # Fit data to model\n",
    "    #model.fit(datagen.flow(X_train[train], y_train[train], batch_size=4),\n",
    "    history = model.fit(X_train[train], y_train[train],\n",
    "                        batch_size = 8,\n",
    "                        epochs=35,\n",
    "                        callbacks=[callback],\n",
    "                        verbose = 1,\n",
    "                        class_weight={0:6.0, 1:0.5}\n",
    "                       )\n",
    "    \n",
    "    scores = model.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {i}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    #filename = './models/model_cnn' + str(i) + '.h5'\n",
    "    #model.save(filename)\n",
    "    #print('>Saved %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Provide average scores ==\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "    print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
