{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN model\n",
    "## _NoCv93.75 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idg = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    "    rotation_range = 30,  \n",
    "    zoom_range = 0.2, \n",
    "    width_shift_range=0.1,  \n",
    "    height_shift_range=0.1,  \n",
    "    horizontal_flip = True,\n",
    ")\n",
    "test_idg = ImageDataGenerator(\n",
    "    rescale = 1./255.\n",
    ")\n",
    "val_idg = ImageDataGenerator(\n",
    "    rescale=1./255.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "train = train_idg.flow_from_directory('./input/chest_xray/train', \n",
    "                                      class_mode='binary',\n",
    "                                      color_mode=\"grayscale\",\n",
    "                                      target_size = IMG_SIZE\n",
    "                                     )\n",
    "test = test_idg.flow_from_directory('./input/chest_xray/test', \n",
    "                                    class_mode='binary',\n",
    "                                    color_mode=\"grayscale\",\n",
    "                                    target_size = IMG_SIZE\n",
    "                                   )\n",
    "val = val_idg.flow_from_directory('./input/chest_xray/val',\n",
    "                                  class_mode='binary',\n",
    "                                  color_mode=\"grayscale\",\n",
    "                                  target_size = IMG_SIZE\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY = train.next()\n",
    "testX, testY = test.next()\n",
    "valX, valY = val.next()\n",
    "\n",
    "print(len(trainX), len(trainY))#32 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X=(32, 224, 224, 1) Y=(32,)\n",
      "Test X=(32, 224, 224, 1) Y=(32,)\n",
      "Val X=(16, 224, 224, 1) Y=(16,)\n"
     ]
    }
   ],
   "source": [
    "print('Train X=%s Y=%s' %(trainX.shape, trainY.shape))\n",
    "print('Test X=%s Y=%s' %(testX.shape, testY.shape))\n",
    "print('Val X=%s Y=%s' %(valX.shape, valY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prettyus17/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['Normal' if label == 0 else 'Pneumonia' for label in trainY]\n",
    "sns.countplot(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 222, 222, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 186624)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               47776000  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 47,827,970\n",
      "Trainable params: 47,827,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32 , (3,3)  , activation = 'relu' , input_shape = (224, 224,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "163/163 [==============================] - 204s 1s/step - loss: 0.3770 - accuracy: 0.8311 - val_loss: 0.6550 - val_accuracy: 0.6250\n",
      "Epoch 2/20\n",
      "163/163 [==============================] - 137s 842ms/step - loss: 0.2921 - accuracy: 0.8675 - val_loss: 1.0434 - val_accuracy: 0.6250\n",
      "Epoch 3/20\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.2667 - accuracy: 0.8831\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.2667 - accuracy: 0.8831 - val_loss: 1.0468 - val_accuracy: 0.6250\n",
      "Epoch 4/20\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.2263 - accuracy: 0.9070 - val_loss: 0.8373 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "163/163 [==============================] - 138s 847ms/step - loss: 0.2071 - accuracy: 0.9178 - val_loss: 0.6842 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.2017 - accuracy: 0.9158 - val_loss: 0.3942 - val_accuracy: 0.8125\n",
      "Epoch 7/20\n",
      "163/163 [==============================] - 137s 843ms/step - loss: 0.1989 - accuracy: 0.9181 - val_loss: 0.9420 - val_accuracy: 0.6250\n",
      "Epoch 8/20\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.9199\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.2016 - accuracy: 0.9199 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "163/163 [==============================] - 137s 843ms/step - loss: 0.1747 - accuracy: 0.9335 - val_loss: 0.4562 - val_accuracy: 0.8125\n",
      "Epoch 10/20\n",
      "163/163 [==============================] - 138s 844ms/step - loss: 0.1543 - accuracy: 0.9402 - val_loss: 0.3052 - val_accuracy: 0.8750\n",
      "Epoch 11/20\n",
      "163/163 [==============================] - 137s 841ms/step - loss: 0.1547 - accuracy: 0.9396 - val_loss: 0.2959 - val_accuracy: 0.8750\n",
      "Epoch 12/20\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9429\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "163/163 [==============================] - 137s 842ms/step - loss: 0.1423 - accuracy: 0.9429 - val_loss: 0.3107 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.1451 - accuracy: 0.9425 - val_loss: 0.4450 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.9484\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "163/163 [==============================] - 137s 841ms/step - loss: 0.1414 - accuracy: 0.9484 - val_loss: 0.3601 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.1399 - accuracy: 0.9500 - val_loss: 0.3276 - val_accuracy: 0.8750\n",
      "Epoch 16/20\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.1378 - accuracy: 0.9473\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "163/163 [==============================] - 137s 842ms/step - loss: 0.1378 - accuracy: 0.9473 - val_loss: 0.3137 - val_accuracy: 0.8750\n",
      "Epoch 17/20\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.1435 - accuracy: 0.9471 - val_loss: 0.3353 - val_accuracy: 0.8750\n",
      "Epoch 18/20\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9490\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "163/163 [==============================] - 137s 843ms/step - loss: 0.1359 - accuracy: 0.9490 - val_loss: 0.3043 - val_accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.1382 - accuracy: 0.9469 - val_loss: 0.3237 - val_accuracy: 0.8750\n",
      "Epoch 20/20\n",
      "163/163 [==============================] - 138s 844ms/step - loss: 0.1408 - accuracy: 0.9469 - val_loss: 0.3153 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train ,batch_size=8, epochs = 20 , validation_data = val ,callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9375\n",
      "Loss of the model is -  0.14821916818618774\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9375\n",
      "Accuracy of the model is -  93.75 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss of the model is - \" , model.evaluate(testX,testY)[0])\n",
    "print(\"Accuracy of the model is - \" , model.evaluate(testX,testY)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR CV_CNN(Simple  test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './input/chest_xray/'\n",
    "# define paths\n",
    "train_normal_dir = path + 'train/NORMAL/'\n",
    "train_pneu_dir = path + 'train/PNEUMONIA/'\n",
    "\n",
    "test_normal_dir = path + 'test/NORMAL/'\n",
    "test_pneu_dir = path + 'test/PNEUMONIA/'\n",
    "\n",
    "val_normal_dir = path + 'val/NORMAL/'\n",
    "val_pneu_dir = path + 'val/PNEUMONIA/'\n",
    "\n",
    "# find all files, our files has extension jpeg\n",
    "train_normal_cases = glob.glob(train_normal_dir + '*jpeg') #1341\n",
    "train_pneu_cases = glob.glob(train_pneu_dir + '*jpeg')#3875\n",
    "\n",
    "test_normal_cases = glob.glob(test_normal_dir + '*jpeg')#234\n",
    "test_pneu_cases = glob.glob(test_pneu_dir + '*jpeg')#390\n",
    "\n",
    "val_normal_cases = glob.glob(val_normal_dir + '*jpeg')#8\n",
    "val_pneu_cases = glob.glob(val_pneu_dir + '*jpeg')#8\n",
    "\n",
    "\n",
    "# make path using / instead of \\\\ ... this may be redudant step\n",
    "train_normal_cases = [x.replace('\\\\', '/') for x in train_normal_cases]\n",
    "train_pneu_cases = [x.replace('\\\\', '/') for x in train_pneu_cases]\n",
    "test_normal_cases = [x.replace('\\\\', '/') for x in test_normal_cases]\n",
    "test_pneu_cases = [x.replace('\\\\', '/') for x in test_pneu_cases]\n",
    "val_normal_cases = [x.replace('\\\\', '/') for x in val_normal_cases]\n",
    "val_pneu_cases = [x.replace('\\\\', '/') for x in val_pneu_cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists for train, test & validation cases, create labels as well\n",
    "train_list = []\n",
    "test_list = []\n",
    "val_list = []\n",
    "\n",
    "for x in train_normal_cases:\n",
    "    train_list.append([x, 0])\n",
    "\n",
    "for x in train_pneu_cases:\n",
    "    train_list.append([x, 1])  \n",
    "\n",
    "for x in test_normal_cases:\n",
    "    test_list.append([x, 0])  \n",
    "\n",
    "for x in test_pneu_cases:\n",
    "    test_list.append([x, 1])  \n",
    "\n",
    "for x in val_normal_cases:\n",
    "    val_list.append([x, 0])  \n",
    "\n",
    "for x in val_pneu_cases:\n",
    "    val_list.append([x, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle/randomize data as they were loaded in order: normal cases, then pneumonia cases\n",
    "random.shuffle(train_list)\n",
    "random.shuffle(test_list)\n",
    "random.shuffle(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes\n",
    "train_df = pd.DataFrame(train_list, columns=['image', 'label'])\n",
    "test_df = pd.DataFrame(test_list, columns=['image', 'label'])\n",
    "val_df = pd.DataFrame(val_list, columns=['image', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize distribution of cases_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.countplot(train_df['label'])\n",
    "plt.title('Train data')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.countplot(test_df['label'])\n",
    "plt.title('Test data')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.countplot(val_df['label'])\n",
    "plt.title('Validation data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**여기서 class_weight 조절의 필요성을 생각해볼 필요가 있음.. \n",
    "**학습 데이터를 보면 정상 자료가 비정상 환자 자료에 비에 부족한 편  \n",
    "**딥러닝에서 클래스 불균형을 다루는 방법  \n",
    "\n",
    "현실 데이터에는 클래스 불균형 (class imbalance) 문제가 자주 있다.   \n",
    "어떤 데이터에서 각 클래스 (주로 범주형 반응 변수) 가 갖고 있는 데이터의 양에 차이가 큰 경우,   \n",
    "\"현실 데이터\" 에 클래스 불균형 문제가 있다고 말한다.  \n",
    "\n",
    "- 더욱 큰 비중 (weight) 를 두고 정확한 예측을 할 수 있도록 만들어야한다.  \n",
    "- 각 데이터에서 loss 를 계산할 때 특정 클래스의 데이터에 더 큰 loss 값을 갖도록 하는 방법  \n",
    "- 정상환자 클래스의 데이터에 관해서는 loss 가 더 크도록 만드는 것이다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing_cv  \n",
    "\n",
    "process_data - 이미지 로드, 크기 조정, 그레이스케일로 변환, 정규화 및 텐서 흐름에 필요한 차원으로 재조정  \n",
    "compose_dataset - 이미지를 반복하여 2 Numpy 배열 생성. 첫째는 이미지 자체를 매트릭스로 포함하며, 둘째는 레이블을 포함함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = img/255.0\n",
    "    img = np.reshape(img, (224, 224,1))\n",
    "   \n",
    "    return img\n",
    "\n",
    "def compose_dataset(df):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for img_path, label in df.values:\n",
    "        data.append(process_data(img_path))\n",
    "        labels.append(label)\n",
    "       \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (5216, 224, 224, 1), Labels shape: (5216,)\n",
      "Test data shape: (624, 224, 224, 1), Labels shape: (624,)\n",
      "Validation data shape: (16, 224, 224, 1), Labels shape: (16,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = compose_dataset(train_df)\n",
    "X_test, y_test = compose_dataset(test_df)\n",
    "X_val, y_val = compose_dataset(val_df)\n",
    "\n",
    "print('Train data shape: {}, Labels shape: {}'.format(X_train.shape, y_train.shape))\n",
    "print('Test data shape: {}, Labels shape: {}'.format(X_test.shape, y_test.shape))\n",
    "print('Validation data shape: {}, Labels shape: {}'.format(X_val.shape, y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight decay\n",
    "가중치 감소는 학습 중에 가중치가 큰 것에 대해서는 일종의 패널티를 부과해 과적합의 위험을 줄이는 방법이다. 가중치의 제곱 법칙(L2 법칙; 많이 사용된다)를 손실함수에 더해 손실함수 값이 더 커지게 한다. 그만큼 가중치가 커지는 것을 억제하기 되는 것이다.\n",
    "\n",
    "\n",
    "\n",
    "L2 법칙은 1/2곱하기 λ(람다) 곱하기 W제곱 이다.\n",
    "\n",
    "람다는 정규화의 세기를 조절하는 하이퍼파라미터이다.\n",
    "\n",
    "람다를 크게 설정할수록 가중치에 대한 페널티가 커진다. \n",
    "\n",
    "\n",
    "출처: https://sacko.tistory.com/45 [데이터 분석하는 문과생, 싸코]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.9448173005219984, 1: 0.6730322580645162}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[1 0 1 ... 0 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "weights = {0: weights[0], 1: weights[1]}\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.3333333333333333, 1: 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1\n",
      " 1 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0\n",
      " 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1\n",
      " 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1\n",
      " 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 0 1\n",
      " 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1\n",
      " 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0\n",
      " 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 1 0 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0\n",
      " 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1\n",
      " 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0\n",
      " 0 1 1 1 1 0 1 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0\n",
      " 1 1 1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0\n",
      " 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "weights = compute_class_weight('balanced', np.unique(y_test), y_test)\n",
    "weights = {0: weights[0], 1: weights[1]}\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.0, 1: 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 0 0 1 1 1 0 0 0 1 0 1 0 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "weights = compute_class_weight('balanced', np.unique(y_val), y_val)\n",
    "weights = {0: weights[0], 1: weights[1]}\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range = 0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n",
    "\n",
    "# fit generator on our train features\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kfold  Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Model configuration\n",
    "img_width, img_height, img_num_channels = 224, 224, 1 #gray image channel = 1\n",
    "loss_function = sparse_categorical_crossentropy\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling_CV(Simple test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32 , (3,3)  , activation = 'relu' , input_shape = (224, 224,1)))    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))##sigmoid or softmax \n",
    "    # compile model\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    ## 최적화 adam or rmsprop..+loss sparse_categorical_crossentropy or binary\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Kfold #1\n",
      "Epoch 1/20\n",
      "142/522 [=======>......................] - ETA: 4:33 - loss: 1.6020 - accuracy: 0.4489"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-9d41dfd16301>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Fit data to model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#model.fit(datagen.flow(X_train[train], y_train[train], batch_size=4),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     history = model.fit(X_train[train], y_train[train],\n\u001b[0m\u001b[0;32m     11\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1130\u001b[0m                 _r=1):\n\u001b[0;32m   1131\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1132\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1133\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    823\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2969\u001b[0m       (graph_function,\n\u001b[0;32m   2970\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2971\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2972\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1945\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1946\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1947\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1948\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1949\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    554\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    557\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, (train, test) in enumerate(kfold.split(X_train, y_train), 1):\n",
    "   \n",
    "    print(f'Training model for Kfold #{i}')\n",
    "    callback = EarlyStopping(monitor='loss', patience=6)\n",
    "   \n",
    "    model = get_model()\n",
    "\n",
    "    # Fit data to model\n",
    "    #model.fit(datagen.flow(X_train[train], y_train[train], batch_size=4),\n",
    "    history = model.fit(X_train[train], y_train[train],\n",
    "                        validation_data=(X_train[test], y_train[test]),\n",
    "                        batch_size = 8,\n",
    "                        epochs=20,\n",
    "                        callbacks=[callback],\n",
    "                        verbose = 1,\n",
    "                        class_weight={0:6.0, 1:0.5}\n",
    "                       )\n",
    "   \n",
    "    scores = model.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {i}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "   \n",
    "    filename = './models/model_Simplecnn' + str(i) + '.h5'\n",
    "    model.save(filename)\n",
    "    print('>Saved %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Provide average scores ==\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "    print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(list):\n",
    "    return (sum(list)/len(list))\n",
    "\n",
    "print(\"Test loss  : {}\".format(avg(loss_per_fold)))\n",
    "print(\"Test accuracy : {}\".format(avg(acc_per_fold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['accuracy', 'loss']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
