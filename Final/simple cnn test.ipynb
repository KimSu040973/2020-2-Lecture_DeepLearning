{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN model\n",
    "## _NoCv93.75 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idg = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    "    rotation_range = 30,  \n",
    "    zoom_range = 0.2, \n",
    "    width_shift_range=0.1,  \n",
    "    height_shift_range=0.1,  \n",
    "    horizontal_flip = True,\n",
    ")\n",
    "test_idg = ImageDataGenerator(\n",
    "    rescale = 1./255.\n",
    ")\n",
    "val_idg = ImageDataGenerator(\n",
    "    rescale=1./255.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "train = train_idg.flow_from_directory('./input/chest_xray/train', \n",
    "                                      class_mode='binary',\n",
    "                                      color_mode=\"grayscale\",\n",
    "                                      target_size = IMG_SIZE\n",
    "                                     )\n",
    "test = test_idg.flow_from_directory('./input/chest_xray/test', \n",
    "                                    class_mode='binary',\n",
    "                                    color_mode=\"grayscale\",\n",
    "                                    target_size = IMG_SIZE\n",
    "                                   )\n",
    "val = val_idg.flow_from_directory('./input/chest_xray/val',\n",
    "                                  class_mode='binary',\n",
    "                                  color_mode=\"grayscale\",\n",
    "                                  target_size = IMG_SIZE\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY = train.next()\n",
    "testX, testY = test.next()\n",
    "valX, valY = val.next()\n",
    "\n",
    "print(len(trainX), len(trainY))#32 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X=(32, 224, 224, 1) Y=(32,)\n",
      "Test X=(32, 224, 224, 1) Y=(32,)\n",
      "Val X=(16, 224, 224, 1) Y=(16,)\n"
     ]
    }
   ],
   "source": [
    "print('Train X=%s Y=%s' %(trainX.shape, trainY.shape))\n",
    "print('Test X=%s Y=%s' %(testX.shape, testY.shape))\n",
    "print('Val X=%s Y=%s' %(valX.shape, valY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prettyus17/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['Normal' if label == 0 else 'Pneumonia' for label in trainY]\n",
    "sns.countplot(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 222, 222, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 186624)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               47776000  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 47,827,970\n",
      "Trainable params: 47,827,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32 , (3,3)  , activation = 'relu' , input_shape = (224, 224,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "163/163 [==============================] - 204s 1s/step - loss: 0.3770 - accuracy: 0.8311 - val_loss: 0.6550 - val_accuracy: 0.6250\n",
      "Epoch 2/20\n",
      "163/163 [==============================] - 137s 842ms/step - loss: 0.2921 - accuracy: 0.8675 - val_loss: 1.0434 - val_accuracy: 0.6250\n",
      "Epoch 3/20\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.2667 - accuracy: 0.8831\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.2667 - accuracy: 0.8831 - val_loss: 1.0468 - val_accuracy: 0.6250\n",
      "Epoch 4/20\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.2263 - accuracy: 0.9070 - val_loss: 0.8373 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "163/163 [==============================] - 138s 847ms/step - loss: 0.2071 - accuracy: 0.9178 - val_loss: 0.6842 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.2017 - accuracy: 0.9158 - val_loss: 0.3942 - val_accuracy: 0.8125\n",
      "Epoch 7/20\n",
      "163/163 [==============================] - 137s 843ms/step - loss: 0.1989 - accuracy: 0.9181 - val_loss: 0.9420 - val_accuracy: 0.6250\n",
      "Epoch 8/20\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.9199\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.2016 - accuracy: 0.9199 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "163/163 [==============================] - 137s 843ms/step - loss: 0.1747 - accuracy: 0.9335 - val_loss: 0.4562 - val_accuracy: 0.8125\n",
      "Epoch 10/20\n",
      "163/163 [==============================] - 138s 844ms/step - loss: 0.1543 - accuracy: 0.9402 - val_loss: 0.3052 - val_accuracy: 0.8750\n",
      "Epoch 11/20\n",
      "163/163 [==============================] - 137s 841ms/step - loss: 0.1547 - accuracy: 0.9396 - val_loss: 0.2959 - val_accuracy: 0.8750\n",
      "Epoch 12/20\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9429\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "163/163 [==============================] - 137s 842ms/step - loss: 0.1423 - accuracy: 0.9429 - val_loss: 0.3107 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.1451 - accuracy: 0.9425 - val_loss: 0.4450 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.9484\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "163/163 [==============================] - 137s 841ms/step - loss: 0.1414 - accuracy: 0.9484 - val_loss: 0.3601 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.1399 - accuracy: 0.9500 - val_loss: 0.3276 - val_accuracy: 0.8750\n",
      "Epoch 16/20\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.1378 - accuracy: 0.9473\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "163/163 [==============================] - 137s 842ms/step - loss: 0.1378 - accuracy: 0.9473 - val_loss: 0.3137 - val_accuracy: 0.8750\n",
      "Epoch 17/20\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.1435 - accuracy: 0.9471 - val_loss: 0.3353 - val_accuracy: 0.8750\n",
      "Epoch 18/20\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9490\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "163/163 [==============================] - 137s 843ms/step - loss: 0.1359 - accuracy: 0.9490 - val_loss: 0.3043 - val_accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "163/163 [==============================] - 138s 845ms/step - loss: 0.1382 - accuracy: 0.9469 - val_loss: 0.3237 - val_accuracy: 0.8750\n",
      "Epoch 20/20\n",
      "163/163 [==============================] - 138s 844ms/step - loss: 0.1408 - accuracy: 0.9469 - val_loss: 0.3153 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train ,batch_size=8, epochs = 20 , validation_data = val ,callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9375\n",
      "Loss of the model is -  0.14821916818618774\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9375\n",
      "Accuracy of the model is -  93.75 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss of the model is - \" , model.evaluate(testX,testY)[0])\n",
    "print(\"Accuracy of the model is - \" , model.evaluate(testX,testY)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR CV_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './input/chest_xray/'\n",
    "# define paths\n",
    "train_normal_dir = path + 'train/NORMAL/'\n",
    "train_pneu_dir = path + 'train/PNEUMONIA/'\n",
    "\n",
    "test_normal_dir = path + 'test/NORMAL/'\n",
    "test_pneu_dir = path + 'test/PNEUMONIA/'\n",
    "\n",
    "val_normal_dir = path + 'val/NORMAL/'\n",
    "val_pneu_dir = path + 'val/PNEUMONIA/'\n",
    "\n",
    "# find all files, our files has extension jpeg\n",
    "train_normal_cases = glob.glob(train_normal_dir + '*jpeg') #1341\n",
    "train_pneu_cases = glob.glob(train_pneu_dir + '*jpeg')#3875\n",
    "\n",
    "test_normal_cases = glob.glob(test_normal_dir + '*jpeg')#234\n",
    "test_pneu_cases = glob.glob(test_pneu_dir + '*jpeg')#390\n",
    "\n",
    "val_normal_cases = glob.glob(val_normal_dir + '*jpeg')#8\n",
    "val_pneu_cases = glob.glob(val_pneu_dir + '*jpeg')#8\n",
    "\n",
    "\n",
    "# make path using / instead of \\\\ ... this may be redudant step\n",
    "train_normal_cases = [x.replace('\\\\', '/') for x in train_normal_cases]\n",
    "train_pneu_cases = [x.replace('\\\\', '/') for x in train_pneu_cases]\n",
    "test_normal_cases = [x.replace('\\\\', '/') for x in test_normal_cases]\n",
    "test_pneu_cases = [x.replace('\\\\', '/') for x in test_pneu_cases]\n",
    "val_normal_cases = [x.replace('\\\\', '/') for x in val_normal_cases]\n",
    "val_pneu_cases = [x.replace('\\\\', '/') for x in val_pneu_cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists for train, test & validation cases, create labels as well\n",
    "train_list = []\n",
    "test_list = []\n",
    "val_list = []\n",
    "\n",
    "for x in train_normal_cases:\n",
    "    train_list.append([x, 0])\n",
    "\n",
    "for x in train_pneu_cases:\n",
    "    train_list.append([x, 1])  \n",
    "\n",
    "for x in test_normal_cases:\n",
    "    test_list.append([x, 0])  \n",
    "\n",
    "for x in test_pneu_cases:\n",
    "    test_list.append([x, 1])  \n",
    "\n",
    "for x in val_normal_cases:\n",
    "    val_list.append([x, 0])  \n",
    "\n",
    "for x in val_pneu_cases:\n",
    "    val_list.append([x, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle/randomize data as they were loaded in order: normal cases, then pneumonia cases\n",
    "random.shuffle(train_list)\n",
    "random.shuffle(test_list)\n",
    "random.shuffle(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes\n",
    "train_df = pd.DataFrame(train_list, columns=['image', 'label'])\n",
    "test_df = pd.DataFrame(test_list, columns=['image', 'label'])\n",
    "val_df = pd.DataFrame(val_list, columns=['image', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = img/255.0\n",
    "    img = np.reshape(img, (224, 224,1))\n",
    "   \n",
    "    return img\n",
    "\n",
    "def compose_dataset(df):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for img_path, label in df.values:\n",
    "        data.append(process_data(img_path))\n",
    "        labels.append(label)\n",
    "       \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (5216, 224, 224, 1), Labels shape: (5216,)\n",
      "Test data shape: (624, 224, 224, 1), Labels shape: (624,)\n",
      "Validation data shape: (16, 224, 224, 1), Labels shape: (16,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = compose_dataset(train_df)\n",
    "X_test, y_test = compose_dataset(test_df)\n",
    "X_val, y_val = compose_dataset(val_df)\n",
    "\n",
    "print('Train data shape: {}, Labels shape: {}'.format(X_train.shape, y_train.shape))\n",
    "print('Test data shape: {}, Labels shape: {}'.format(X_test.shape, y_test.shape))\n",
    "print('Validation data shape: {}, Labels shape: {}'.format(X_val.shape, y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range = 0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n",
    "\n",
    "# fit generator on our train features\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Model configuration\n",
    "img_width, img_height, img_num_channels = 224, 224, 1 #gray image channel = 1\n",
    "loss_function = sparse_categorical_crossentropy\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32 , (3,3)  , activation = 'relu' , input_shape = (224, 224,1)))    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='softmax'))##sigmoid or softmax \n",
    "    # compile model\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    ## 최적화 adam or rmsprop..+loss sparse_categorical_crossentropy or binary\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for Kfold #1\n"
     ]
    }
   ],
   "source": [
    "for i, (train, test) in enumerate(kfold.split(X_train, y_train), 1):\n",
    "   \n",
    "    print(f'Training model for Kfold #{i}')\n",
    "    callback = EarlyStopping(monitor='loss', patience=6)\n",
    "   \n",
    "    model = get_model()\n",
    "\n",
    "    # Fit data to model\n",
    "    #model.fit(datagen.flow(X_train[train], y_train[train], batch_size=4),\n",
    "    history = model.fit(X_train[train], y_train[train],\n",
    "                        batch_size = 8,\n",
    "                        epochs=20,\n",
    "                        callbacks=[callback],\n",
    "                        verbose = 1,\n",
    "                        class_weight={0:6.0, 1:0.5}\n",
    "                       )\n",
    "   \n",
    "    scores = model.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {i}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "   \n",
    "    filename = './models/model_Diseasecnn' + str(i) + '.h5'\n",
    "    model.save(filename)\n",
    "    print('>Saved %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Provide average scores ==\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "    print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(list):\n",
    "\n",
    "    return (sum(list) / len(list))\n",
    "\n",
    "print(\"Test acc : {}\".format(average(acc_per_fold)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
